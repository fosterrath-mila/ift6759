# Utility modules

You will have to write many functions during this project that may contain common and reusable
code snippets. Such snippets (once properly tested!) are always nice to keep around in some
kind of 'utility' module. We decided to provide a few useful functions just like that which
may help you develop visualization and debugging tools faster. Some of them might also be 
necessary should you decide to create your own data packaging strategy based on HDF5 or
compressed images. You can find them [here](https://github.com/mila-iqia/ift6759/blob/master/projects/project1/utils.py).

Some of the noteworthy utility functions are detailed below. Besides, always consider these
functions as "potentially buggy" unless you understand them and have tested them yourself!
Finally, feel free to modify and add functions to the ``utils.py`` module as you wish. In
any case, make sure you install the proper dependencies for some of the functions before
using them (e.g. OpenCV, matplotlib).

## Compressing and decompressing numpy arrays

Your data loading strategy might require you to extract and repackage useful data from the
NetCDF or HDF5 files we provide in order to save disk space and/or speed up processing. If
you use the HDF5 files, you will have to manually decompress the information stored in them
first. If you want to create new HDF5 files, you might have to compress the data again.

For compression, we provide a simple utility function (``compress_array``) that converts
numpy arrays into byte strings that can be stored in dynamic-length HDF5 datasets. For
decompression, we provide a compatible invert operation (``decompress_array``) which will
convert the byte string back into a numpy array. In both cases, depending on the encoding
used, you might have to import various 3rd-party dependencies into your code (e.g. OpenCV,
LZ4, TensorFlow).

## Reading numpy arrays from HDF5 files

The HDF5 archives we provide contain compressed numpy arrays as detailed  
[here](https://github.com/mila-iqia/ift6759/blob/master/projects/project1/datasources.md).
To properly reload these arrays, we provide a utility function (``fetch_hdf5_sample``)
that can be used on an already-opened HDF5 archive. The "sample index" argument
given to that function corresponds to the offset encoded into the metadata dataframes
described [here](https://github.com/mila-iqia/ift6759/blob/master/projects/project1/dataframe.md).

## Visualizing the content of an HDF5 file

Both 8-bit and 16-bit HDF5 archives can be visualized using the provided ``viz_hdf5_imagery``
function. This may help you understand the role of each available imagery channel and the
impact of cloud cover over a measurement station.

The animation shown in the project presentation is obtained using this function with 8-bit
imagery for June 21st, 2010, and for the following channels: ``["ch1", "ch2", "ch3", "ch4", "ch6"]``. 

## Visualizing GHI predictions

Finally, we provide a function to display GHI plots (measured values, clearsky estimates,
and predicted values) for a set of station over different time horizons: ``viz_predictions``.
In this case, the function expects to receive the text file generated by the evaluation
script ([described here](https://github.com/mila-iqia/ift6759/blob/master/projects/project1/evaluation.md))
which contains your model's raw predictions for a set of timestamps. These timestamps must
also be provided through the test configuration file, for which you also have an example
[here](https://github.com/mila-iqia/ift6759/blob/master/projects/project1/dummy_test_cfg.json).

Feel free to ignore this function and instead only rely on its subfunctions (``draw_daily_ghi``
and ``plot_ghi_curves``) if you want to incorporate it into your own code.
